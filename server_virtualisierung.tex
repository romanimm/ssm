\chapter{Server-Virtualisierung}

\section{Unix Systemsoftware}

\subsection{System-Struktur}
Die System-Struktur ist auf der Abbildung \ref{fig:system-software-system-struktur} ersichtlich. Das Dateisystem ist für gewöhnlich hierarchisch gegliedert. Speziell: Auf Linux-Systemen werden Peripherie-Geräte als Files behandelt, unter /dev für device.

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{0.4\textwidth}
		\includegraphics[width=\textwidth]{fig/system-software-system-struktur}
		\caption{System-Struktur}
		\label{fig:system-software-system-struktur}
	\end{subfigure}
	~
	\begin{subfigure}[b]{0.5\textwidth}
		\includegraphics[width=\textwidth]{fig/system-software-systemkern}
		\caption{System-Struktur}
		\label{fig:system-software-systemkern}
	\end{subfigure}
\end{figure}

\subsubsection{Interrupt-Prioriäten}
\begin{enumerate}
	\item Maschinenfehler (höchste)
	\item Zeitgeber
	\item Disk
	\item Netzwerk
	\item Terminals
	\item Software-Interrupts (niedrigste)
\end{enumerate}

\subsubsection{Prozess-Elemente}
Ein Prozess kann einzigartig identifiziert werden durch: Identifier (PID), State, Priority, Program Counter, Memory Pointers, Context data, I/O Status infos, accounting infos. Ein Programm ist eine ausführbare Datei. Ein Prozess ist ein in Ausführung befindendes Programm.

\paragraph{Prozess-Kontrol-Block} Enthält die oben genanten Prozess-Elemente. Wenn man alle Elemente eines Prozess hat, kann man diesen quasi schlafen legen (unterbrechen) und später wieder ausführen. Für den Prozess selber ist es so, als wäre er nie unterbrochen worden. Erzeugt und verwaltet durch das OS.

\paragraph{Prozess-Status}
\begin{description}
	\item[Trace (verfolgt):] Zeichnet die Instruktionen eines Prozess auf und kann in aufgrund dessen charakterisieren.
	\item[Dispatcher (verteilt):] Kleines Programm, welches die Prozesse auf dem Prozessor wechselt. Der Scheduler entscheidet welcher Prozess der nächste ist und der Dispatcher entzieht dann dem aktuellen Prozess die CPU und übergibt sie an den nächsten Prozess.
\end{description}

\paragraph{Queuing Modell} Das OS arbeitet intern mit Queues um die Prozesse zu verwalten. Die unterschiedlichen Prozess Status sind als Queues implementiert (Ready-Queue, Blocked-Queue, usw.). Und sobald wieder einer an den Prozessor darf, kann er aus der Ready-Queue genommen werden. Muss der Prozess auf ein Event warten wird er in eine separate Event-Queue verschoben. Tritt das Event dann auf wird er von der Event-Queue in die Ready-Queue verschoben.

\paragraph{OS Control Tables} Für die einzelnen Ressourcen werden Tabellen unterhalten, wie Memory Tables, I/O Tables, File Tables, Prozess Tables.

\paragraph{Process Control Structures}
Um einen Prozess zu verwalten, muss das OS folgendes wissen:
\begin{description}
	\item[Prozess Location] Ein oder mehrere Programme zum Ausführen. Genug Memory um Programm und dessen Daten zu halten. Einen Stack!
	\item[Prozess Attributes] Als \emph{Prozess Image} (Abbildung \ref{fig:system-software-prozess-image}) wird die Sammlung der Programme, Daten, Stack und Attributen bezeichnet. Jeder Prozess hat zudem diverse Attribute, welche sich pro OS unterscheiden können.
\end{description}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.2\linewidth]{fig/system-software-prozess-image}
	\caption{Prozess-Image}
	\label{fig:system-software-prozess-image}
\end{figure}

\paragraph{Virtueller zur physikalischem Adress-Übersetzung}
Wird mittels MMU (Memory Management Unit) gelöst. Mappt physical pages to virtual pages.

\paragraph{Wechsel von Prozess Status}
Ein Prozessor wechselt in einen anderen Status (z.B. bei Interrupt von Running in Ready). Abbildung \ref{fig:system-software-prozess-wechsel} zeigt diesen Statuswechsel.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth]{fig/system-software-prozess-wechsel}
	\caption{Prozess-Wechsel Vorgang}
	\label{fig:system-software-prozess-wechsel}
\end{figure}

\paragraph{UNIX Process Status}
In UNIX gibt es folgende Prozess Status (MEP):
\begin{description}
	\item[User Running] Ausführung im User Mode.
	\item[Kernel Running] Ausführung im Kernel Mode.
	\item[Ready to Run, in Memory] Bereit zur Ausführung, sobald von Scheduler ausgewählt.
	\item[Asleep in Memory] Prozess blockiert bis ein Event auftritt (blocked).
	\item[Ready to Run, Swapped] Der Prozess ist bereit, aber der Swapper muss den Prozess vor der Ausführung vom Swap in den Hauptspeicher laden.
	\item[Sleeping, Swapped] Prozess blockiert bis ein Event auftritt befindet sich aber im Swap.
	\item[Preempted] Der Prozess möchte gerade vom Kernel in den User Mode wechseln, wird aber vom Kernel verdrängt damit dieser einen anderen Prozess abarbeiten kann.
	\item[Created] Prozess wird erzeugt aber ist noch nicht lauffähig.
	\item[Zombie] Prozess existiert nicht mehr, hinterlässt aber eine Spur für seine Eltern-Prozesse.
\end{description}
Wenn im Hauptspeicher zu wenig Platz ist wird ein Prozess ins Swap ausgelagert. Der Swap wird vom Kernel in der Harddisk erzeugt. Abbildung \ref{fig:system-software-state-engine-processes-unix} zeigt die Übergänge der Prozess Status.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\linewidth]{fig/system-software-state-engine-processes-unix}
	\caption{State Engine Processes in UNIX}
	\label{fig:system-software-state-engine-processes-unix}
\end{figure}

\newpage

\subsection{Prozess erzeugen}
Prozess wird mittels Kernel system call \texttt{fork()} erzeugt. Anschliessend werden folgende Schritte durchgegangen:
\begin{enumerate}
	\item Freien Platz in der Prozesstabelle reservieren
	\item PID für den Prozess vergeben (der neue Prozess ist zwangsweise ein Child-Prozess)
	\item Kopiere Parent-Prozess Image mit Ausnahme des ''gesharten'' Memory
	\item Zähler für die Files inkrementieren. Um aufzuzeigen, dass ein zusätzlicher Prozess nun auf die Files zugreift.
	\item Prozess in ready-to-run Queue einfügen
	\item PID vom Child-Prozess zum Parent-Prozess übergeben (return value of \texttt{fork()}). Der Child-Prozess bekommt den Wert 0.
\end{enumerate}
Nachdem der Prozess erzeugt ist, ist er wie jeder andere Prozess. Kann also auch dispatched werden.

\subsection{Unterbrechung von Prozessen}
Es gibt diverse Varianten um Prozesse während der Ausführung zu unterbrechen:
\begin{description}
	\item[Interrupt] Externes Event tritt ein, bei der Ausführung einer Instruktion. Damit können asynchrone Events abgehandelt werden.
	\item[Trap] Verknüpft mit der Ausführung der aktuellen Instruktion. Behandlung eines Fehlers oder einer Ausnahme.
	\item[Supervisor call] Expliziter Request. Aufruf einer OS-Funktion.
\end{description}
Speziell zu erwähnen ist, dass wir zwischen Benutzer-Stack (user) und System-Stack (kernel) unterscheiden.

\subsubsection{System-Calls}
System-Calls sind die Schnittstelle zwischen dem Betriebssystem und dem Benutzerprogramm. Wir stellen uns eine Single-Core Maschine vor. Der aktuelle Prozess arbeitet gerade im Benutzermodus. Nun will er einen Systemaufruf (lesen einer Datei) machen. Dazu muss eine Unterbrechung oder eine spezielle Systemaufruf-Anweisung durchführen. Dadurch wird die Kontrolle an das BS übergeben. Der Kern führt den Systemcall aus und gibt nach Abschluss die Kontrolle wieder an den User Prozess zurück. Ein Systemcall ist wie eine gewöhnliche Prozedur, jedoch können nur Systemcalls in den Kern eintreten, gewöhnliche nicht.

In der Abbildung \ref{fig:system-software-ablauf-c-read} wird ein Trap ausgeführt in Schritt 6. Da wechselt das Programm vom Benutzermodus in den Kernelmodus. Im Schritt 9 wird kein Trap mehr durchgeführt, das zurückspringen passiert wie bei einer normalen Funktion.

Der Systemcall kann den Aufrufer auch weiterhin blockieren. Wenn das Anwenderprogramm nämlich Input von der Tastatur möchte (mittels Systemcall) und nichts kommt, dann blockiert das BS und lässt andere Prozesse arbeiten.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\linewidth]{fig/system-software-ablauf-c-read}
	\caption{System-Call am Beispiel von C read}
	\label{fig:system-software-ablauf-c-read}
\end{figure}

\subsection{Prozess-Kontext}
Wir unterscheiden zwischen drei Bereichen:
\begin{description}
	\item[Benutzer Kontext] Zugewiesener Adressraum und Daten.
	\item[Hardware Kontext] Multitasking relevant. Inhalte der CPU Register, Seitentabellen etc.
	\item[System Kontext] OS Sicht. PID, geöffnete Dateien, Info Eltern und Kind Prozesse, Prioritäten etc. 
\end{description}

\paragraph{File-Deskriptoren}
Jedes geöffnete File erhält eine ID. Jeder Prozess hat seine eigene File Deskriptoren Tabelle, welche eine Sammlung von Pointer ist zu den I/O Streams.

Standardmässig gibt es folgende Streams: \texttt{stdin} (z.B. Keyboard), \texttt{stdout} (z.B. Display) und \texttt{stderr} (z.B. Fehlermeldung auf Display).

Diese Standard-Kanäle können umgebogen werden. Mittels \texttt{>} oder \texttt{|}

\subsection{Threads}
Die Idee kennen wir. Leichtgewichtige Threads vs. schwergewichtige Prozesse. Unter einem einzigen Prozess können mehrere Threads laufen. Im Gegensatz zu Prozessen ist die Erzeugung, Beendigung und Wechsel zwischen Threads um einiges schneller. Auch die Kommunikation ist auf natürlich weise mit dem gemeinsamen Prozess Kontext gegeben.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth]{fig/system-software-single-threaded-vs-muli-threaded}
	\caption{Single Threaded vs. Multi-Threaded}
	\label{fig:system-software-single-threaded-vs-muli-threaded}
\end{figure}

\subsubsection{Thread-Kontext}
Ein Prozess besteht aus mind. 1 Thread. Threads vom gleichen Prozess teilen sich Codesegmente, Datensegmente und Dateideskriptoren. Jeder Thread hat seinen Stack (User und Kernel Stack) und seinen Code Pointer.

\subsubsection{Thread-Arten}
\begin{description}
	\item[User Level Threads (ULT)]
	Thread Mgmt. in der Applikation. Der Kern hat keine Kenntnis über die Existenz von Threads. Arbeiten komplett im User Space. Müssen Kontrolle von sich aus abgegeben. Neigen mehr zu kooperativem als zu preemptiven Scheduling. Implementieren manchmal das Scheduling selber (z.B. frühere Versionen von Java.).
	Dafür gibt es ein paar Vorteile: Thread Wechsel verlangt keinen Kernel Modus, Scheduling applikationspezifisch (Programmierer kann beeinflussen), ULTs laufen auf jedem OS.
	\item[Kernel Level Threads (KLT)]
	Thread Mgmt. vom Kern. Windows verfolgt diesen Ansatz. Der Kern kann mehrere Threads vom gleichen Prozess auf mehrere Prozessoren verteilen (Scheduling). Wenn ein Thread blockiert ist, kann ein Thread vom gleichen Prozess berücksichtigt werden. Kern Prozeduren können multithreaded ausgeführt werden.
\end{description}

\subsubsection{Kombinierter Ansatz}
Oft kommt wohl eine Kombination zum Zug. Thread Erzeugung und generelles Thread Management wird von der Applikation gemacht. Der Rest ist Kernel Sache. Solaris ist ein Vertreter. Die User Level Threads müssen an die Kernel Prozess geheftet werden. Daher wurde eine weitere Schicht eingeführt, die sogenannten LWP (lightweigh process). Die User-Threads werden den LWPs zugeführt. Nur die Threads auf den LWPs sind aktiv. Dabei beinhaltet die LWPs die Kernel Level Threads, welche für die Kernel Level Tasks verwendet werden. Das OS verwendet schlussendlich wirklich nur die Kernel Level Threads. Systemcalls müssen nicht über die Kernel Threads erledigt werden, sondern werden direkt weitergeleitet.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth]{fig/system-software-aufbau-2-level-threading}
	\caption{Aufbau Zwei Level Threading}
	\label{fig:system-software-aufbau-2-level-threading}
\end{figure}

\subsubsection{Windows-Prozesse}
Prozesse existieren als Objekte. Werden als neue oder als Kopie bestehender Prozesse erzeugt. Kann pro Prozess auch mehrere Threads beinhalten. Sowohl Prozesse wie auch Threads haben eingebaute Synchronisierungs-Mechanismen.

\section{Virtuelle Maschinen}
Überall kann man Virtualisierung einsetzen. Ob bei Server, Speicher, Applikation, Desktops oder Netzwerk. Mit Virtualisierung will man die Abstraktion von der darunterliegende Gerätschaft erreichen (Ressourcenmanagement). Im Zusammenhang mit der Virtualisierung fällt auch oft der Begriff Partitionierung (Aufteilung eines Dinges in mehrere unabhängige Elemente).

\newpage

\subsection{Virtualisierungsarten}
\label{sec:virtualisierungsarten}
\begin{description}
	\item[HW Partitionierung:] Teuer, nur noch auf High End Computer anzutreffen. Wie IBM/z, p Systems
	\item[HW Virtualisierung:] Mittels Hypervisor.
	\item[OS Virtualisierung:] Junge, leichtgewichtige Virtualisierungsart.
\end{description}

\subsection{Gründe für eine HW Virtualisierung}
\label{sec:gruende-hw-virtualisierung}
\begin{itemize}
	\item Ressourcen Optimierung
	\item Konsolidierung von Ressourcen
	\item Maximierung der Uptime
	\item Schutz der Applikation von Serverausfällen
	\item Einfache Migration wenn Anforderungen wechseln
	\item Schutz der Investitionen in existierende ''legacy Systeme'' 
\end{itemize}

\subsection{Geschichte}
IBM virtualisiert auf den Mainframes bereits in den 60er Jahren. Die Virtualisierung der x86-Systeme wurde erst 1999 eingeführt, durch VMWare. Citrix hat 2007 mit Xen/Xen-Server virtualisiert und Mircosoft im 2008 mit Window Server 2008 und Hyper-V.

\subsection{Was bedeutet Virtualisierung?}
\label{sec:was-bedeutet-virtualisierung}
\begin{description}
	\item[Emulation:] Ein System ahmt das Verhalten eines anderes Systems nach, d.h. eine x86 CPU kann eine PowerPC CPU emulieren (langsam weil alles übersetzt werden muss).
	\item[Simulation:] Zeigt wie sich ein Modell über eine gewisse Zeitspanne verhält.
	\item[Virtualität:] Eigenschaft einer Sache, nicht in der Form zu existieren, in der sie zu existieren scheint.
	\item[Virtualisierung:] Im Prinzip ähnlich zur Emulation, allerdings werden dabei nicht alle Komponenten des zu virtualisierenden tatsächlich emuliert, sondern z.B. CPU Instruktionen laufen direkt auf der CPU und I/O Geräte werden emuliert.
\end{description}

\subsection{VMM - Virtual Machine Monitor (Hypervisor)}
\label{sec:vmm-virtual-machine-monitor}
Die VM ist die Umgebung erzeugt vom VMM. Die VMM ist eine System Software Schicht und besteht aus folgenden drei Teilen:
\begin{description}
	\item[Dispatcher] dessen Initial Instruction am Speicherplatz liegt wohin die HW trapped.
	\item[Allocator] der entscheidet wer welche Systemressourcen bekommt. Er hat 1 oder n Member (VM).
	\item[Interpreter] für alle Instruktionen die trappen, eine Interpreter Routine pro privilegierte Instruktion.
\end{description}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.4\linewidth]{fig/vmm}
	\caption{VMM}
	\label{fig:vmm}
\end{figure}

\subsection{Instruktionsklassifikation}
Es gibt zwei Betriebsmodis.
\begin{itemize}
	\item Uneingeschränkter Supervisor Modus
	\item Eingeschränkter User Modus
\end{itemize}
Eine privilegierte Instruktion verursacht einen Trap im User Modus. Im Supervisor Modus gibt es keinen Trap. Kontrollkritische Instruktionen (control sensitive) versuchen die Config der Systemressourcen zu ändern.

\subsection{Trap}
Ein \textit{Trap} ist eine Form eines Interrupt, d.h. er unterbricht das laufende Programm, springt zu einer anderen, vordefinierten Memorystelle, macht dort irgendwas und kehrt anschliessend zum Programm zurück. Manchmal gleichbedeutend mit \textit{Exception} oder \textit{Fault}.

\subsection{Challenges beim Betrieb einer VMM}
Die Challenges gelten wohl für die VMM und nicht für den Sysadmin, der das System betreibt.
\begin{itemize}
	\item BS und APP wissen nicht, dass eine VMM existiert.
	\item VMM sollte SW Stack gegenüber anderen VMs isolieren.
	\item VMM sollte vor allen anderen Gast-SW geschützt laufen.
	\item VMM sollte eine ''virtuelle Plattform Interface'' zu den Gast-SW präsentieren.
\end{itemize}

\newpage

\subsection{Vorteile (Hypervisor) Virtualisierung}
Abbildung \ref{fig:vorteile-hypervisor-virtualisierung} zeigt, welche Vorteile die Hypervisor Technologie mitbringt. \emph{Wordload Embedding} ist ein von Microsoft eingeführter Begriff, welcher das optimieren von zwei Applikationen durch den Hypervisor meint.
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.7\linewidth]{fig/vorteile-hypervisor-virtualisierung}
	\caption{Vorteile Hypervisor Virtualisierung}
	\label{fig:vorteile-hypervisor-virtualisierung}
\end{figure}

\subsection{X86-Virtualisierung}
\subsubsection{Die drei Anforderungen von Popek und Goldberg}
\label{sec:popek-goldberg-anforderungen}
\begin{description}
	\item[Gleichheit] Jedes Programm liefert dasselbe Resultat, egal in welchem System es ausgeführt wird.
	\item[Effektivität] Wann immer möglich sollen Instruktionen ohne Umwege via VMM auf dem physischen Prozessor ausgeführt werden.
	\item[Ressourcenkontrolle] Der VMM hat die komplette Kontrolle über die physikalischen Ressourcen wie Memory oder I/O, jedoch nicht zwingend über die Prozessoraktivität. Es muss für jedes Programm unmöglich sein die System Ressourcen (wie verfügbares Memory) direkt zu beeinflussen. Der Verteiler (Allocator) muss dazu jedesmal aufgerufen werden.
\end{description}

\subsubsection{Gleichheit - Homomorphismus - MEP}
\begin{figure}[]
\centering
\includegraphics[width=0.7\linewidth]{fig/popek_goldberg_mapping}
\caption{Mapping von Instruktionen einer virtuellen Maschine}
\label{fig:popek_goldberg_mapping}
\end{figure}
Die mathematische Definition der Virtualisierung ist grundsätzlich nichts anderes als das Gleichheits-Prinzip, welches bereits kurz besprochen wurde. Leider ist es Prüfungsrelevant.

Man studiere Abbildung \ref{fig:popek_goldberg_mapping}. Wir haben links ein reales System und rechts ein virtuelles. Das virtuelle System ist ein Bild vom realen System. Die blauen Punkte sind Zustände und die Funktion $ e_{i} $ Übergänge zwischen 2 Zuständen. Die Funktion $ f() $ stellt nun die Abbildungsfunktion zwischen dem realen und dem virtuellem System dar. Wenn zwischen den Zuständen auf dem realen System $ S_{i} $ und $ S_{j} $ nun ein Übergang stattfindet, so muss der neue Zustand im virtuellen System abgebildet, derselbe sein wie wenn vom abgebildeten Ursprungszustand ein Übergang stattgefunden hätte. Dies wird ja durch die Pfeile verdeutlicht. Eine solche Abbildung ist nun eine Homomorphismus, denn eine homomorphe Abbildung erhält die Strukturen des Ursprungsbildes, hier die Übergänge zwischen den Zuständen.

\subsubsection{Theorem 1}
\label{sec:poppek-goldberg-theorem1}
Eine virtuelle Maschine soll ja laut Popek und Goldberg ihre Instruktionen möglichst direkt auf dem Prozessor laufen lassen könne, um bestmögliche Perfomance zu garantieren. Bestimmte Instruktionen wie die Memory Allokation können allerdings nicht direkt zur CPU, sondern müssen via den Virtual Machine Monitor (VMM). Jetzt können wir ja nicht für jede Instruktion überprüfen, ob diese zugelassen ist (zu aufwendig), daher nutzen wir die Tatsache aus, dass privilegierte Instruktionen getrappt werden können, d.h. abgefangen. Jetzt müssen nur noch alle Instruktionen, welche das korrekte Funktionieren der VMM beeinträchtigen könnten, auch privilegierte Instruktionen sein, damit sie abgefangen werden können. Und genau das besagt das erste Theorem.

\subsubsection{Theorem 2}
Eine beliebige Prozessorarchitekturen der dritten Generation ist rekursiv virtualisierbar, wenn sie selbst virtualisierbar ist und für sie ein VMM ohne Zeitabhängigkeiten konstruiert werden kann.
Einige Architekturen, wie zum Beispiel die x86-Architektur ohne hardwaregestütze Virtualierungsfunktionen, erfüllen diese Bedingungen nicht, weswegen sie nicht auf dem klassischen Weg virtualisierbar sind.

\subsubsection{Hypervisor}
Das Problem ist, dass man nicht mehrere BS auf einem physikalischen Rechner laufen lassen kann, da ein BS dazu konstruiert ist, alle verfügbaren Ressourcen zu managen. Daher braucht es eine Zwischenschicht, welche die BS isoliert. Das BS erfährt somit keine Änderung. Der Hypervisor kommt zum Zug. Abbildung \ref{fig:hypervisor-types} zeigt die zwei Typen von Hypervisoren (Virtual Machine Monitor)

\begin{figure}[h!]
\centering
\includegraphics[width=0.8\linewidth]{fig/hypervisor-types}
\caption{Hypervisor Arten}
\label{fig:hypervisor-types}
\end{figure}

\newpage

\subsection{HW-Virtualisierung}

\subsubsection{Direct Exceution}
Es gibt Sicherheitsringe. Die x86 Architektur kennt 4 Ringe. User Level Programme laufen im Ring 3. Das OS braucht HW Zugriff und läuft auf Ring 0. Eine Virtualisierungsschicht muss unter Ring 0 gelegt werden oder es braucht eine Schnittstelle vom Hypervisor mit speziellen Befehlssatz. 
\begin{figure}[h!]
\centering
\includegraphics[width=0.3\linewidth]{fig/sicherheitsringe}
\caption{Sicherheitsringe}
\label{fig:sicherheitsringe}
\end{figure}
CPU hat mittels den Sicherheitsringe die Möglichkeiten ob die Instruktionen auch das entsprechende Privileg haben. Der Prozess hat die Möglichkeiten mittels eines Algorithmus zu prüfen ob die Instruktionen von einem privilegierten Memory Segment kommen.

\subsubsection{Binary Translation}
Im Mainframe wird für jede privilegierte Instruktion ein Trap ausgeführt. Der VMM fängt diese Instruktion ab und emuliert diese. Im x86 ISA sind nicht alle privilegierten Instruktionen Trap geschützt z.B. POPF. Wird diese bswp. im Ring 1 ausgeführt, interessiert das die CPU nicht und wird einfach nicht ausgeführt. Insgesamt gibt es 17 solcher ''nicht abgefanger'' Instruktionen. Das wäre allerdings eine Verletzung des ersten Theorems! Abhilfe schafft die binary Translation von VMWare (patentiert!).

In Abbildung \ref{fig:binary-translation-virt} sieht man, dass es eine Kombination zwischen direkter Ausführung und binary Translation ist. User Level Code wird direkt ausgeführt. Übersetzer Kernel Code ersetzt nicht virtualisierbare Instruktionen. Dazu ist keine Hardware oder Unterstüzung des Gast OS benötigt, denn das Gast OS hat keine Ahnung dass es in einer VM läuft. User Applikationen laufen direkt und werden nur übersetzt, wenn der Gast OS Kernel aufgerufen wird.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.3\linewidth]{fig/binary-translation-virt}
	\caption{Binary Translation Virtualisation}
	\label{fig:binary-translation-virt}
\end{figure}

Diese Binary Translation funktioniert nach dem Prinzip, dass der Code vom Kernel des Betriebssystems nach sensitiven Operationen durchsucht wird, der danach mit speziellem Code vom VMM ersetzt wird. Um die Performance zu erhalten, werden diese Blocks gechached. Trotzdem braucht ein solcher translated system call 2308 Prozessorzyklen, wobei ein native Systemcall lediglich 242 benötigen würde.

\subsubsection{Para Virtualisation (SW Assist)}
Da VMWare ja das Patent auf binary translation besitzt, musste Xen eine Alternative zur x86 Trap-Problematik finden. Anstatt nun System Calls zur Laufzeit zu Übersetzen, wie das Binary Translation macht, müssen nun diese statisch im Source Code ersetzt werden. Dabei kommt das Hypercall Interface zum Einsatz, um direkt mit dem Hypervisor kommunizieren zu können. Da keine Übersetzung zur Laufzeit gemacht werden muss, ist dieser Ansatz zwar schneller, dafür müssen die Betriebssysteme extra angepasst werden. Somit laufen auch keine unmodifizierten Betriebssysteme.
\begin{figure}[h!]
\centering
\includegraphics[width=0.2\linewidth]{fig/sw-virtualisierung-ringe}
\caption{Software unterstützte Virtualisierung}
\label{fig:sw-virtualisierung-ringe}
\end{figure}

\subsubsection{Full Virtualisation (HW Assist)}
\label{sec:hw-unterstuetzt-virt}
VMM und VM haben getrennte Addressbereiche. Dafür musste man neue Operationsmodis kreieren. VMX root (voll privilegiert für VMM) und VMX non-root (nicht voll privilegiert, für Gast-VM). Dies reduziert die Gast-VM SW Privilegien ohne auf die Ringe zurückgreifen zu müssen. Dieser neue CPU Modus erlaubt Ringe unterhalb Ring 0. Privlegierte Operatonion gelangen so direkt zum Hypervisor. Der Gast Status wird in virtual machine control structures abgespeichert.
\begin{figure}[h!]
\centering
\includegraphics[width=0.3\linewidth]{fig/hw-virtualisierung-ringe}
\caption{Hardware-Virtualisierung Ringe}
\label{fig:hw-virtualisierung-ringe}
\end{figure}

\paragraph{VMM Lifecycle}
\label{sec:vmm-lifecycle}
\begin{description}
	\item[VM Entry] Übergang VMM zu Gast. Eintritt von VMX non-root Operationen.
	\item[VMLaunch] Instruktionen werden beim initialen Eintritt verwendet. 
	\item[VMResume] Instruktionen werden beim nachfolgenden Eintritten verwendet.
	\item[VM Exit] Übergang von Gast zu VMM. Eintritt in VMX root Operationen. Speichert Gast Status in VMCS.
\end{description}

\subsection{Memory-Virtualisierung}
Physikalisch mapped das OS virtual Page Number zu physical Page Number. Eine VM denkt, dass es physisches Memory vor sich hat und kann so agieren. Aber dieses Memory wird durch den Hypervisor verwaltet. Das gesamte Memory der Maschine wird durch alle VMs geteilt. Der Dreh- und Angelpunkt ist der Hypervisor.

\subsubsection{Memory Verbrauch}
\label{sec:ballooning}
Man kann mit folgenden Möglichkeiten Memory sparen, auch bekannt als Memory Rückgewinnungstechnologien:
\begin{description}
	\item[Page Sharing] In homogenen Gast Systemen findet sich viele identische Pages. Algorithmus: Scan all pages, Hash per page, Hash-Collision means same page, check byte by byte, mark as read only. Falls nun doch einer schreiben möchte, wird dies kopiert.
	\item[Page Patching] ''Fast gleiche'' Pages gibt es sehr viele. Bei nur wenig Differenz von Pages werden die als ''fast gleich'' beurteilt. VM 1 arbeitet schlussendlich mit der echten Page. Die VM 2 arbeitet schlussendlich mit der Page von der VM 1 und einer Differenz, welches Teil einer anderen Page ist.
	\item[Page Compression] Es gibt viele Pages die in naher Zukunft nicht verwendet werden. Diese können komprimiert werden.
	
	\item[Ballooning] Vergesst die Papers von Bruno (wirklich!). Es ist simpel. Ballooning erlaubt es dem Hypervisor ungenutztes Memory von den VMs abzuziehen und es anderen VMs zur Verfügung zu stellen. Ein Beispiel: Wir haben mehrere VMs mit 8GB alloziert. Die meisten verwenden jedoch nur 4GB effektiv. Nun braucht eine einzelne aber gerade für einen intensiven Prozess 12GB. Nun kommt die Ballooning Technologie zum Einsatz. Der Hypervisor nimmt von den anderen VMs das nicht gebrauchte Memory und stellt es der VM zur Verfügung, welche es tatsächlich braucht. Da das Gast-BS innerhalb der VM läuft, weiss es nicht wie der Total Amount of Memory des physischen Hosts ist. Ballooning macht dem Gast-BS bewusst, über die Speicherknappheit des Hosts. Achtung: Auf der VM muss ein Balloon-Treiber installiert sein.
\end{description}

\section{OS Virtualisierung}
''Hypervisors are the living proof of operating systems's incompetence''. Hypervisor dienen dazu um die Mängel der OS auszugleichen. Nun kommt die OS Virtualisierung, die Antwort der OS Hersteller.
Es werden keine Hypervisor verwendet, also kein ''Trap and Emulate''. Braucht daher auch nur ganz wenige zusätzliche Prozessorzyklen, es wird nur ein Kern verwendet! (Solaris kann auch mit mehreren Kernen arbeiten)

\subsection{Container / Zone}
Eine Instanz eines virtuellen OS wird Container (Linux) oder Zone (Solaris) genannt. Eine virtuelle OS Instanz ohne eingeschalteten Ressourcen Mgmt. ist nicht für die Produktion geeignet.

\subsection{VMs vs. Container}
VMs sind schwergewichtig, Container sind leichtgewichtig. Die Provisionierung (Bereitstellung) einer VM dauert einiges länger als eines Containers!
\begin{figure}[h!]
\centering
\includegraphics[width=0.7\linewidth]{fig/vms-vs-containers}
\caption{VMs vs. Containers}
\label{fig:vms-vs-containers}
\end{figure}

\subsection{Was kann die OS Virtualisierung?}
\begin{itemize}
	\item Feingranulare Kontrolle der individuellen Prozesse und Applikationen.
	\item Sichere Isolation von Applikationen.
	\item Transparente Migration von Applikationen (siehe Docker) möglich. (Anmerkung: Der Hypervisior migriert nur ganze OS Instanzen.)
\end{itemize}

\subsection{Was kann OS Virtualisierung nicht?}
\begin{itemize}
	\item Keine fremden OS möglich. Auf Windows kann ich nur Windows bringen.
	\item Zonen müssen auf dem selben Patch Level laufen wie OS/Kern.
	\item Anforderungen an SysAdmin steigen.
	\item Ressourcen Mgmt. muss eingeschalten werden (Solaris).
\end{itemize}

\subsection{Container-Architektur}
\begin{figure}[h!]
\centering
\includegraphics[width=0.7\linewidth]{fig/container-architektur}
\caption{Container-Architektur}
\label{fig:container-architektur}
\end{figure}

\subsection{Beispiel: Linux OS Virtualisierung}
\subsubsection{VServer}
Eine sehr leichtgewichtige Art der OS Virtualisierung. Es benötigt nur eine Instanz des Linux Kernel. VServer benötigt nur ein paar wenige Modifikationen im Kern und ein paar OS Userland Tools. Der Kern verwaltet alle System Ressourcen. Alle virtuellen OS Instanzen sind isoliert von einander:
\begin{description}
	\item[chroot] - File System Isolation - Damit wird das Root-Directory (/) an einen anderen Ort gelegt. Das modifizierte Umfeld nennt man chroot jail.
	\item[chcontext] - Process Isolation - Ein Linux Utilty, welches einen neuen Security Kontext erzeugt und die Kommandos darin ausführt. Jede OS Instanz verfügt über einen eigenen Prozess-Ausführungskontext.
	\item[chbind] - Network Isolation - Dieses Kommando ist ein System Call. Lockt den resultierend Prozess mit seinen Kinder zu einer spezifischen IP Adresse.
	\item[capablities] - Root User Isolation - Partitioniert die Privilegien eines Root-Users. 
\end{description}

\subsection{Isolation}
Linux Container - Es braucht also drei wichtige Erweiterungen.
\begin{description}
	\item[chroot] Filesystemgrenze für Prozesse
	\item[cgroups] - Ressourcen sharing zwischen Prozess Gruppen - Kernel Feature - Erlauben das feingranulare Allozieren von System Ressourcen wie CPU, Memory, Disk über eine Gruppe von Prozessen. CGroups sind hierarchisch gegliedert. Child erbt von Parent. Da alle Prozesse aus der init-Prozess ein Child von einem anderen Prozess ist, nennt man das Mono-Hierarchie (Einzel-Baum).  Beim Erzeugen eines Child-Prozess erbt der Prozess den Umgebungskontext wie die PATH Variabel uvw. vom Parent. Im Unterschied zum herkömmlichen Modell (single-tree), haben wir mit cgroups mehrere unanbhängige Prozess-Bäume. Bsp: memory (setzt limiten auf den Memory Vebrauch), freezer, devices usw.
	\item[ns] - Namespaces - Die Implementation von Container ist eine offensichtliche Verwendung von Namespaces. Ein Namespace abstrahiert eine globale Ressource in der Art, dass der zum Namespace gehörende Prozess meint, ihm gehört die Ressource einzigartig. Änderungen an der globalen Ressourcen sind nur sichtbar für diejenigen, welche im gleichen Namensraum sind. Bsp: PID namespaces isolieren den Prozess ID Namensraum (pro Container unique, aber so mehrere init Prozess mit ID 1 über mehrere Container möglich). Weitere User namespaces, Network, IPC, UTS, Mount namespaces.
\end{description} 

\subsection{Docker}
Wir kennen nun die Linux Container. Mit Docker geht man eine Stufe tiefer. Ein Host hat n-Base Images. Das ist das OS wie Ubuntu, Redhat. Pro Base-Image kann man VMs hinzufügen. Eine VM repräsentiert eine Applikation. Wie PHP, MySQL, Wordpress. Docker verwendet die Möglichkeit von LXC. Solche Container sind read-only und hoch portierbar. Dies ist ein Software-Layer über dem LCX. Dockt wortwörtlich an jedes Linux an.